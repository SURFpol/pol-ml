{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vereiste imports\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from keras import applications, optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os, keras, cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zorg voor reproduceerbaarheid door gebruik te maken van een seed-waarde.\n",
    "\n",
    "keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=42)\n",
    "\n",
    "# Leg de afmetingen van de input-afbeeldingen vast.\n",
    "\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "# Locatie dataset.\n",
    "\n",
    "train_data_dir = '/path/to/data/here'\n",
    "\n",
    "# Leg het aantal epochs en de batch size vast.\n",
    "\n",
    "epochs_run1 = 10\n",
    "epochs_run2 = 10\n",
    "batch_size = 16\n",
    "\n",
    "# Voorbereidingen voor data augmentation, genereren van train- en test-afbeeldingen\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=5,\n",
    "    zoom_range=0,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2) # set validation split\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation')\n",
    "\n",
    "# Implementeer early stopping. \n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_acc', min_delta=0.001, patience=4, mode='auto', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN 1 - Train alleen het eigen deel van het netwerk.\n",
    "\n",
    "# Importeer VGG16, het neurale netwerk dat we gebruiken voor transfer learning.\n",
    "\n",
    "base_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(img_width,img_height,3))\n",
    "print('Base model loaded.')\n",
    "\n",
    "# Voeg het 'eigen' deel van het netwerk toe.\n",
    "\n",
    "x = Flatten(name='flatten')(base_model.output)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(4, activation='softmax')(x) # Aanpasbaar naar aantal categorieen.\n",
    "model = Model(inputs= base_model.input, outputs=x)\n",
    "print('This is the number of trainable weights '\n",
    "      'before freezing part of the network:', len(model.trainable_weights))\n",
    "\n",
    "# Bevries de eerste 20 lagen van het netwerk.\n",
    "\n",
    "for layer in model.layers[:20]:\n",
    "    layer.trainable = False\n",
    "    print('This is the number of trainable weights '\n",
    "      'after freezing part of the network:', len(model.trainable_weights))\n",
    "\n",
    "# Print overzicht van het netwerk.\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Compile het model, learning rate kan aangepast worden.\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train het netwerk.\n",
    "\n",
    "model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=train_generator.samples // batch_size,\n",
    "                    epochs=epochs_run1,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps= validation_generator.samples // batch_size,\n",
    "                    verbose=1, callbacks = [early_stop])\n",
    "\n",
    "# Sla de resultaten op.\n",
    "\n",
    "model.save('run1.h5')\n",
    "model.save_weights('run1-weights.h5')\n",
    "print('Run 1 saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN 2 - Train eigen deel van het netwerk en het laatste deel van het geimporteerde netwerk.\n",
    "\n",
    "# Initialiseer een checkpoint voor het opslaan van de gewichten van het netwerk.\n",
    "\n",
    "checkpoint = ModelCheckpoint('run2_best_weights.h5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto', period=1)\n",
    "\n",
    "# Importeer het model uit run 1.\n",
    "\n",
    "model_copy = keras.models.load_model('run1.h5')\n",
    "\n",
    "# Maak het laatste deel van het geimporteerde netwerk trainable.\n",
    "\n",
    "for layer in model_copy.layers:\n",
    "    layer.trainable = True\n",
    "for layer in model_copy.layers[:15]:\n",
    "    layer.trainable = False\n",
    "model_copy.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "model_copy.load_weights('run1-weights.h5')\n",
    "print('This is the number of trainable weights '\n",
    "      'after unfreezing part of the network:', len(model_copy.trainable_weights))\n",
    "\n",
    "# Print overzicht van het netwerk.\n",
    "\n",
    "model_copy.summary()\n",
    "\n",
    "# Train het netwerk.\n",
    "\n",
    "M = model_copy.fit_generator(train_generator,\n",
    "                        steps_per_epoch=train_generator.samples // batch_size,\n",
    "                        epochs=epochs_run2,\n",
    "                        validation_data=validation_generator,\n",
    "                        validation_steps=validation_generator.samples // batch_size,\n",
    "                        verbose=1, callbacks = [early_stop,checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leg het verloop van de accuracy en loss vast\n",
    "\n",
    "acc = M.history['acc']\n",
    "val_acc = M.history['val_acc']\n",
    "loss = M.history['loss']\n",
    "val_loss = M.history['val_loss']\n",
    "num_epochs = range(len(acc))\n",
    "\n",
    "# Visualizeer verloop accuracy\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, epochs_run2), M.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, epochs_run2), M.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(num_epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(num_epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# Visualizeer verloop loss\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, epochs_run2), M.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, epochs_run2), M.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.title(\"Training Loss on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(num_epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(num_epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizeer de activaties uit het laatste deel van het netwerk\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "def deprocess_image(x):\n",
    "    # normalize tensor: center on 0., ensure std is 0.1\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + 1e-5)\n",
    "    x *= 0.1\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "def generate_pattern(layer_name, filter_index, size=150):\n",
    "    # Build a loss function that maximizes the activation\n",
    "    # of the nth filter of the layer considered.\n",
    "    layer_output = model_copy.get_layer(layer_name).output\n",
    "    loss = K.mean(layer_output[:, :, :, filter_index])\n",
    "\n",
    "    # Compute the gradient of the input picture wrt this loss\n",
    "    grads = K.gradients(loss, model_copy.input)[0]\n",
    "\n",
    "    # Normalization trick: we normalize the gradient\n",
    "    grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
    "\n",
    "    # This function returns the loss and grads given the input picture\n",
    "    iterate = K.function([model_copy.input], [loss, grads])\n",
    "    \n",
    "    # We start from a gray image with some noise\n",
    "    input_img_data = np.random.random((1, size, size, 3)) * 20 + 128.\n",
    "\n",
    "    # Run gradient ascent for 40 steps\n",
    "    step = 1.\n",
    "    for i in range(40):\n",
    "        loss_value, grads_value = iterate([input_img_data])\n",
    "        input_img_data += grads_value * step\n",
    "        \n",
    "    img = input_img_data[0]\n",
    "    return deprocess_image(img)\n",
    "\n",
    "plt.imshow(generate_pattern('block5_conv1', 0))\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laat het netwerk een voorspelling doen op basis van een aangeleverde image\n",
    "# en visualiseer de resultaten\n",
    "\n",
    "# Locatie van de input image\n",
    "\n",
    "img_path = '/path/to/image.jpg'\n",
    "\n",
    "# Locatie waar het gevisualiseerde resultaat kan worden opgeslagen\n",
    "\n",
    "output_path = '/path/to/output.jpg'\n",
    "\n",
    "# `img` is a PIL image of size 224x224\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "\n",
    "# `x` is a float32 Numpy array of shape (224, 224, 3)\n",
    "x = image.img_to_array(img)\n",
    "\n",
    "# We add a dimension to transform our array into a \"batch\" of size (1, 224, 224, 3)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "\n",
    "# Finally we preprocess the batch (this does channel-wise color normalization)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "keys=list(validation_generator.class_indices.keys())\n",
    "y_prob = model_copy.predict(x) \n",
    "y_classes = y_prob.argmax(axis=-1)\n",
    "print('Predicted category:', (keys[(np.asscalar(y_classes))]))\n",
    "\n",
    "# This is the entry in the prediction vector\n",
    "img_output = model_copy.output[:, (np.asscalar(y_classes))]\n",
    "\n",
    "# The is the output feature map of the `block5_conv3` layer, the last convolutional layer in VGG16\n",
    "last_conv_layer = model_copy.get_layer('block5_conv3')\n",
    "\n",
    "# This is the gradient of the predicted class with regard to the output feature map of `block5_conv3`\n",
    "grads = K.gradients(img_output, last_conv_layer.output)[0]\n",
    "\n",
    "# This is a vector of shape (512,), where each entry is the mean intensity of the gradient over a specific feature map channel\n",
    "pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "# This function allows us to access the values of the quantities we just defined:\n",
    "# `pooled_grads` and the output feature map of `block5_conv3`,\n",
    "# given a sample image\n",
    "iterate = K.function([model_copy.input], [pooled_grads, last_conv_layer.output[0]])\n",
    "\n",
    "# These are the values of these two quantities, as Numpy arrays,\n",
    "# given our sample image of two elephants\n",
    "pooled_grads_value, conv_layer_output_value = iterate([x])\n",
    "\n",
    "# We multiply each channel in the feature map array\n",
    "# by \"how important this channel is\" with regard to the elephant class\n",
    "for i in range(512):\n",
    "    conv_layer_output_value[:, :, i] *= pooled_grads_value[i]\n",
    "\n",
    "# The channel-wise mean of the resulting feature map\n",
    "# is our heatmap of class activation\n",
    "heatmap = np.mean(conv_layer_output_value, axis=-1)\n",
    "\n",
    "# Plot heatmap\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "heatmap /= np.max(heatmap)\n",
    "plt.matshow(heatmap)\n",
    "plt.show()\n",
    "\n",
    "# We use cv2 to load the original image\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "# We resize the heatmap to have the same size as the original image\n",
    "heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "\n",
    "# We convert the heatmap to RGB\n",
    "heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "# We apply the heatmap to the original image\n",
    "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "\n",
    "# 0.4 here is a heatmap intensity factor\n",
    "superimposed_img = heatmap * 0.4 + img\n",
    "\n",
    "# Plot image/heatmap\n",
    "plt.imshow(superimposed_img)\n",
    "cv2.imwrite(output_path, superimposed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
